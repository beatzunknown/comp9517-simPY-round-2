{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.1"
    },
    "colab": {
      "name": "velocity.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nr4OMoaWbZj-"
      },
      "source": [
        "# COMP9517 Project: Distance and Velocity Estimation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqvOTKyby1Zm"
      },
      "source": [
        "## Google Colab Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HeLC4RIbevD"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SrijutYN6m-"
      },
      "source": [
        "%cp \"/content/drive/MyDrive/Colab Notebooks/comp9517/condensed_data.zip\" \"/content/\"\n",
        "%cp \"/content/drive/MyDrive/Colab Notebooks/comp9517/mask_rcnn_coco.h5\" \"/content/\"\n",
        "%cp \"/content/drive/MyDrive/Colab Notebooks/comp9517/car_mask_rcnn.h5\" \"/content/\"\n",
        "%cp -r \"/content/drive/MyDrive/Colab Notebooks/comp9517/mrcnn\" \"/content/\"\n",
        "%cp -r \"/content/drive/MyDrive/Colab Notebooks/comp9517/evaluate\" \"/content/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9x2E-X6MWvXz"
      },
      "source": [
        "%cp -r \"/content/benchmark_velocity_test/preds/\" \"/content/drive/MyDrive/Colab Notebooks/comp9517/preds/\" "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJAVKvRybeiD"
      },
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "with ZipFile('/content/condensed_data.zip', 'r') as z:\n",
        "  z.extractall()\n",
        "  print('Done')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjEuIDKtyxUu"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_9CABelbZkH"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDa_QaDHbZkI"
      },
      "source": [
        "import os\n",
        "import json\n",
        "import math\n",
        "import random\n",
        "import pickle\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import mrcnn.utils\n",
        "import mrcnn.config\n",
        "import mrcnn.model\n",
        "import mrcnn.visualize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vqwUTASbZkK"
      },
      "source": [
        "## Constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5m2QvZiZbZkM"
      },
      "source": [
        "COLOR_SPACE = cv2.COLOR_BGR2RGB\n",
        "TRAINING_DIR = os.path.abspath('benchmark_velocity_train/clips/')\n",
        "TESTING_DIR = os.path.abspath('benchmark_velocity_test/clips/')\n",
        "PRETRAINED_WEIGHTS_FILE = 'mask_rcnn_coco.h5'\n",
        "WEIGHTS_FILE = 'car_mask_rcnn.h5'\n",
        "CONCURRENCY_LEVEL = 1 # don't have capacity for any more\n",
        "plt.rcParams['figure.figsize'] = [16, 8]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6_s4MSMbZkP"
      },
      "source": [
        "## Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jc5oICLYbZkS"
      },
      "source": [
        "# Check if two given rectangles are overlapping\n",
        "def is_overlapping(a, b):\n",
        "    ax1, ax2, ay1, ay2 = a\n",
        "    bx1, bx2, by1, by2 = b\n",
        "    \n",
        "    # left side of one is after right side of other\n",
        "    if ax1 >= bx2 or bx1 >= ax2:\n",
        "        return False\n",
        "    \n",
        "    # top side of one is below bottom side of other\n",
        "    if ay1 >= by2 or by1 >= ay2:\n",
        "        return False\n",
        "    \n",
        "    return True\n",
        "\n",
        "def calc_distance(img):\n",
        "    x1, x2, y1, y2 = img\n",
        "    \n",
        "    ## intrinsic matrix params:\n",
        "    fx = 714.1526\n",
        "    fy = 710.3725\n",
        "    cx = 713.85\n",
        "    cy = 327\n",
        "\n",
        "    # extrinsic data\n",
        "    camera_height = 1.80\n",
        "    ave_car_width = 1.80\n",
        "    \n",
        "    #dx2 = fy*camera_height / abs(y2-cy)\n",
        "    dx = ave_car_width * fx / (x2 - x1)\n",
        "    dy = dx*(x2-cx) / fx\n",
        "\n",
        "    return [dx, dy]\n",
        "\n",
        "def calc_velocity_across_imgs(img_a, img_b, step):\n",
        "    time_per_frame = 2/40\n",
        "    dist_a = calc_distance(img_a)\n",
        "    dist_b = calc_distance(img_b)\n",
        "    velo = [(dist_b[0] - dist_a[0]) / (step * time_per_frame),\n",
        "            (dist_b[1] - dist_a[1]) / (step * time_per_frame)]\n",
        "    return velo\n",
        "\n",
        "# final bbox is detection of 40th frame\n",
        "# ie detection in our program output img\n",
        "velo_cache = {}\n",
        "def calc_velocity(clip_num, vid_imgs, final_bbox, step):\n",
        "    step=5\n",
        "    global velo_cache\n",
        "    if (clip_num, final_bbox) in velo_cache:\n",
        "        return velo_cache[(clip_num, final_bbox)]\n",
        "    if not vid_imgs:\n",
        "        return [0, 0]\n",
        "\n",
        "    vx = vy = v_count = 0\n",
        "    velos = []\n",
        "    for i in range(0, 40-step, step):\n",
        "        start = vid_imgs[i]\n",
        "        end = vid_imgs[i+step-1]\n",
        "        if not (start and end):\n",
        "            continue\n",
        "        start_bbox, _ = get_accurate_predictions(start, [final_bbox])[0]\n",
        "        end_bbox, _ = get_accurate_predictions(end, [final_bbox])[0]\n",
        "        if start_bbox and end_bbox:\n",
        "            v = calc_velocity_across_imgs(start_bbox, end_bbox, step-1)\n",
        "            #if not ((-0.0001 <= v[0] <= 0.0001) and (-0.0001 <= v[1] <= 0.0001)):\n",
        "            if (-7 < v[0] < 9) and (-1.5 < v[1] < 1.5):\n",
        "                velos.append(v)\n",
        "            vx += v[0]\n",
        "            vy += v[1]\n",
        "            v_count += 1\n",
        "    \n",
        "    if v_count > 0:\n",
        "        vx /= v_count\n",
        "        vy /= v_count\n",
        "    \n",
        "    velo = [0, 0]\n",
        "    if velos:\n",
        "        velos = sorted(velos, key=lambda x: x[0])\n",
        "        #velos_y = sorted(velos, key=lambda y: y[1])[5:-5]\n",
        "        print(velos)\n",
        "        velo = velos[len(velos)//2]\n",
        "        velo_x = [x[0] for x in velos]\n",
        "        velo_x = sum(velo_x)/len(velo_x)\n",
        "        velo_y = [y[1] for y in velos]\n",
        "        velo_y = sum(velo_y)/len(velo_y)\n",
        "        velo = [velo_x, velo_y]\n",
        "    \n",
        "    velo_cache[(clip_num, final_bbox)] = velo\n",
        "\n",
        "    return velo\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vd5cjDXyqAX"
      },
      "source": [
        "## Data Parsing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOw5bDxMyqUe"
      },
      "source": [
        "# retrieve feature vectors, annotations and images from\n",
        "# a list of labels and data files\n",
        "def parse_data(img_files, label_files, pos_data, velo_data):\n",
        "    match_data, nonmatch_data, annotations, imgs, dists, velos = [], [], [], [], [], []\n",
        "    if pos_data and velo_data:\n",
        "        iter_data = list(zip(img_files, label_files, pos_data, velo_data))\n",
        "    else:\n",
        "        iter_data = list(zip(img_files, label_files))\n",
        "    #random.shuffle(iter_data)\n",
        "\n",
        "    for i, data in enumerate(iter_data):\n",
        "        if pos_data:\n",
        "            img_file, label_file, dists_data, velos_data = data\n",
        "        else:\n",
        "            img_file, label_file = data\n",
        "        label = None\n",
        "        if not os.path.isfile(label_file):\n",
        "            continue\n",
        "        with open(label_file, 'r') as f:\n",
        "            label = json.load(f)\n",
        "        if label is None:\n",
        "            continue\n",
        "            \n",
        "        img = cv2.imread(img_file)\n",
        "        img = cv2.cvtColor(img, COLOR_SPACE)\n",
        "        imgs.append(img)\n",
        "        img_annotations = []\n",
        "        img_dists = []\n",
        "        img_velos = []\n",
        "        \n",
        "        for i, label_bounds in enumerate(label):\n",
        "            bbox = label_bounds['bbox']\n",
        "            x1 = math.floor(bbox['left'])\n",
        "            x2 = math.ceil(bbox['right'])\n",
        "            y1 = math.floor(bbox['top'])\n",
        "            y2 = math.ceil(bbox['bottom'])\n",
        "            if pos_data:\n",
        "                dist = dists_data[i]\n",
        "                velo = velos_data[i]\n",
        "            else:\n",
        "                dist = (label_bounds['position'][0], label_bounds['position'][1])\n",
        "                velo = (label_bounds['velocity'][0], label_bounds['velocity'][1])\n",
        "            img_dists.append(dist)\n",
        "            img_velos.append(velo)\n",
        "            #calculated = calc_distance((x1,x2,y1,y2))\n",
        "            #print(\"Gt:\", dist)\n",
        "            #print(\"Pred:\", calculated)\n",
        "\n",
        "            img_annotations.append((x1, x2, y1, y2))\n",
        "\n",
        "        \n",
        "        annotations.append(img_annotations)\n",
        "        dists.append(img_dists)\n",
        "        velos.append(img_velos)\n",
        "    \n",
        "    return (annotations, imgs, dists, velos)\n",
        "\n",
        "def get_data(file_dir):\n",
        "    img_files, label_files, pos_data, velo_data = [], [], [], []\n",
        "    gt_path = os.path.join(file_dir, \"..\", \"gt.json\")\n",
        "    gt_dists, gt_velos = [], []\n",
        "    if os.path.isfile(gt_path):\n",
        "        with open(gt_path, 'r') as f:\n",
        "            gt_data = json.load(f)\n",
        "            for gt in gt_data:\n",
        "                gt_dists.append([(car['position'][0], car['position'][1]) for car in gt])\n",
        "                gt_velos.append([(car['velocity'][0], car['velocity'][1]) for car in gt])\n",
        "    for clip_num in sorted(os.listdir(file_dir), key=lambda x: int(x)):\n",
        "        clip_path = os.path.join(file_dir, clip_num)\n",
        "        if os.path.isdir(clip_path):\n",
        "            img_files.append(os.path.join(clip_path, \"imgs\", \"040.jpg\"))\n",
        "            label_files.append(os.path.join(clip_path, \"annotation.json\"))\n",
        "            if os.path.isfile(gt_path):\n",
        "                pos_data.append(gt_dists[int(clip_num)-1])\n",
        "                velo_data.append(gt_velos[int(clip_num)-1])\n",
        "    \n",
        "    return parse_data(img_files, label_files, pos_data, velo_data)\n",
        "\n",
        "# Get supplementary data (not used at the moment)\n",
        "def get_supp_data(file_dir):\n",
        "    match_data = []\n",
        "    nonmatch_data = []\n",
        "    annotations = []\n",
        "    imgs = []\n",
        "    img_files, label_file = [], os.path.join(file_dir, \"annotation.json\")\n",
        "    with open(label_file, 'r') as f:\n",
        "            label_data = json.load(f)\n",
        "    \n",
        "\n",
        "    for entry in label_data[1000:2000]:\n",
        "        img_file = os.path.join(file_dir, entry['file_name'])\n",
        "        if not os.path.isfile(img_file):\n",
        "            continue\n",
        "        img = cv2.imread(img_file)\n",
        "        img = cv2.cvtColor(img, COLOR_SPACE)\n",
        "        imgs.append(img)\n",
        "        nonmatches = nonmatch_bounds.copy()\n",
        "        \n",
        "        label = entry['bbox']\n",
        "        \n",
        "        for label_bounds in label:\n",
        "            x1 = math.floor(label_bounds['left'])\n",
        "            x2 = math.ceil(label_bounds['right'])\n",
        "            y1 = math.floor(label_bounds['top'])\n",
        "            y2 = math.ceil(label_bounds['bottom'])\n",
        "            annotations.append((x1, x2, y1, y2))\n",
        "            dim_diff = (x2-x1) - (y2-y1)\n",
        "            size = x2 - x1\n",
        "            if x1 >= x2 or y1 >= y2:\n",
        "                continue\n",
        "            y1 -= math.floor(dim_diff/2)\n",
        "            y2 += math.ceil(dim_diff/2)\n",
        "            if y1 < 0 or y2 > img.shape[0]:\n",
        "                continue\n",
        "            #plt.imshow(img)\n",
        "            #plt.show()\n",
        "            #cv2.waitKey(0)\n",
        "            match_img = img[y1:y2, x1:x2]\n",
        "            match_data.append(get_features(match_img))\n",
        "            nonmatches = [n for n in nonmatches if not is_overlapping(n, (x1, x2, y1, y2))]\n",
        "        \n",
        "        for x1, x2, y1, y2 in nonmatches:\n",
        "            nonmatch_img = img[y1:y2, x1:x2]\n",
        "            nonmatch_data.append(get_features(nonmatch_img))\n",
        "    \n",
        "    return (match_data, nonmatch_data, annotations, imgs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "id--93MyJpcF"
      },
      "source": [
        "## Mask R-CNN Class Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtsweIYoJr0N"
      },
      "source": [
        "CLASS_NAMES = ['BG', 'car']\n",
        "\n",
        "class CarDataset(mrcnn.utils.Dataset):\n",
        "    gts = []\n",
        "    \n",
        "    def load_dataset(self, dataset_dir, is_train=True):\n",
        "        self.add_class(\"object\", 1, \"car\")\n",
        "        img_files, label_files, pos_data = [], [], []\n",
        "        self.gts = []\n",
        "        if not is_train:\n",
        "            gt_path = os.path.join(dataset_dir, \"..\", \"gt.json\")\n",
        "            if os.path.isfile(gt_path):\n",
        "                with open(gt_path, 'r') as f:\n",
        "                    gt_data = json.load(f)\n",
        "                    for gt in gt_data:\n",
        "                        self.gts.append([(car['position'][0], car['position'][1]) for car in gt])\n",
        "        for clip_num in os.listdir(dataset_dir):\n",
        "            clip_path = os.path.join(dataset_dir, clip_num)\n",
        "            if os.path.isdir(clip_path):\n",
        "                img_path = os.path.join(clip_path, \"imgs\", \"040.jpg\")\n",
        "                ann_path = os.path.join(clip_path, \"annotation.json\")\n",
        "\n",
        "                self.add_image('object', image_id=clip_num, path=img_path, annotation=ann_path)\n",
        "\n",
        "    def extract_boxes(self, image_id, ann_file):\n",
        "        with open(ann_file, 'r') as f:\n",
        "            annotations = json.load(f)\n",
        "            \n",
        "        boxes, distances = [], []\n",
        "        for annotation in annotations:\n",
        "            bbox = annotation['bbox']\n",
        "            if self.gts:\n",
        "                distance = self.gts[int(image_id)-1]\n",
        "            else:\n",
        "                distance = (annotation['position'][0], annotation['position'][1])\n",
        "            distances.append(distance)\n",
        "            x1 = math.floor(bbox['left'])\n",
        "            x2 = math.ceil(bbox['right'])\n",
        "            y1 = math.floor(bbox['top'])\n",
        "            y2 = math.ceil(bbox['bottom'])\n",
        "            boxes.append((x1, x2, y1, y2))\n",
        "\n",
        "        width = 1280\n",
        "        height = 720\n",
        "        return boxes, width, height, distances\n",
        "\n",
        "    def load_mask(self, image_id):\n",
        "        info = self.image_info[image_id]\n",
        "        ann_file = info['annotation']\n",
        "        boxes, w, h, distances = self.extract_boxes(image_id, ann_file)\n",
        "        masks = np.zeros([h, w, len(boxes)], dtype='uint8')\n",
        "\n",
        "        class_ids = list()\n",
        "        for i in range(len(boxes)):\n",
        "            x1, x2, y1, y2 = boxes[i]\n",
        "            masks[y1:y2, x1:x2, i] = 1\n",
        "            class_ids.append(self.class_names.index('car'))\n",
        "        return masks, np.asarray(class_ids, dtype='int32')\n",
        "\n",
        "\n",
        "class CarConfig(mrcnn.config.Config):\n",
        "    NAME = \"car_cfg\"\n",
        "\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = CONCURRENCY_LEVEL\n",
        "    \n",
        "    NUM_CLASSES = 2\n",
        "\n",
        "    STEPS_PER_EPOCH = 131\n",
        "\n",
        "class InferenceConfig(CarConfig):\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = CONCURRENCY_LEVEL\n",
        "    #IMAGE_MIN_DIM = 512\n",
        "    #IMAGE_MAX_DIM = 512\n",
        "    DETECTION_MIN_CONFIDENCE = 0.85\n",
        "    NUM_CLASSES = len(CLASS_NAMES)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMPvQicXJsFt"
      },
      "source": [
        "## Mask R-CNN Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0qqEzZIJsdV"
      },
      "source": [
        "train_set = CarDataset()\n",
        "train_set.load_dataset(dataset_dir=TRAINING_DIR, is_train=True)\n",
        "train_set.prepare()\n",
        "\n",
        "valid_dataset = CarDataset()\n",
        "valid_dataset.load_dataset(dataset_dir=TRAINING_DIR, is_train=False)\n",
        "valid_dataset.prepare()\n",
        "\n",
        "car_config = CarConfig()\n",
        "\n",
        "model = mrcnn.model.MaskRCNN(mode='training', \n",
        "                             model_dir='./', \n",
        "                             config=car_config)\n",
        "\n",
        "model.load_weights(filepath=PRETRAINED_WEIGHTS_FILE, \n",
        "                   by_name=True, \n",
        "                   exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",  \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
        "\n",
        "model.train(train_dataset=train_set, \n",
        "            val_dataset=valid_dataset, \n",
        "            learning_rate=car_config.LEARNING_RATE, \n",
        "            epochs=1, \n",
        "            layers='heads')\n",
        "\n",
        "model.keras_model.save_weights(WEIGHTS_FILE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOVoHQMV0DVY"
      },
      "source": [
        "## Mask R-CNN Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrBAivMb0DD-"
      },
      "source": [
        "pred_model = mrcnn.model.MaskRCNN(mode=\"inference\", \n",
        "                             config=InferenceConfig(),\n",
        "                             model_dir=os.getcwd())\n",
        "\n",
        "pred_model.load_weights(filepath=WEIGHTS_FILE, by_name=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUSEBEiSbZkh"
      },
      "source": [
        "## Classification & Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwhhDTJqbZkm"
      },
      "source": [
        "from evaluate.velocity import VeloEval\n",
        "\n",
        "# calculated IOU / Jaccard Index\n",
        "def intersection_over_union(a, b):\n",
        "    ax1, ax2, ay1, ay2 = a\n",
        "    bx1, bx2, by1, by2 = b\n",
        "    a_area = (ax2 - ax1) * (ay2 - ay1)\n",
        "    b_area = (bx2 - bx1) * (by2 - by1)\n",
        "\n",
        "    inter_width = min(ax2, bx2) - max(ax1, bx1)\n",
        "    inter_height = min(ay2, by2) - max(ay1, by1)\n",
        "    if inter_width > 0 and inter_height > 0:\n",
        "        inter_area = inter_width * inter_height\n",
        "    else:\n",
        "        inter_area = 0\n",
        "    \n",
        "    union_area = a_area + b_area - inter_area\n",
        "    return inter_area / union_area\n",
        "\n",
        "def get_accurate_predictions(preds, gts):\n",
        "    return [(max(preds, key=lambda p: intersection_over_union(p, gt)), gt) for gt in gts]\n",
        "\n",
        "def calc_euclid_dist(a, b):\n",
        "    return math.sqrt((a[0]-b[0])**2 + (a[1]-b[1])**2)\n",
        "\n",
        "# vehicle prediction evaluation\n",
        "# pred: list of predicted boxes\n",
        "# gt: list of ground truth boxes\n",
        "def evaluate(clip_num, pred, gts, mode='tp', dists=[], velos=[]):\n",
        "    # true positives\n",
        "    num_detected = 0\n",
        "    for gt in gts:\n",
        "        num_detected += any([is_overlapping(p, gt) for p in pred])\n",
        "    tp_eval = num_detected / len(gts)\n",
        "\n",
        "    # false positives\n",
        "    fp_eval = 0\n",
        "    num_fp = len(pred)\n",
        "    if num_fp > 0:\n",
        "        for p in pred:\n",
        "            num_fp -= any([is_overlapping(p, gt) for gt in gts])\n",
        "        fp_eval = num_fp / len(pred)\n",
        "\n",
        "    # jaccard index & distance evaluation\n",
        "    jaccard_eval = distance_eval = velocity_eval = 0\n",
        "    distance_pc_eval = velocity_pc_eval = 1\n",
        "    num_detected = 0\n",
        "    jaccard_sum = distance_sum = distance_pc_sum = velo_sum = velo_pc_sum = 0\n",
        "    if pred:\n",
        "        mappings = get_accurate_predictions(pred, gts)\n",
        "        for pred, gt in mappings:\n",
        "            jaccard = intersection_over_union(pred, gt)\n",
        "            num_detected += 1\n",
        "            jaccard_sum += jaccard\n",
        "            if dists:\n",
        "                gt_dist = dists[gts.index(gt)]\n",
        "                pred_dist = calc_distance(pred)\n",
        "                euclid_dist = calc_euclid_dist(gt_dist, pred_dist)\n",
        "                distance_sum += euclid_dist\n",
        "                distance_pc_sum += (euclid_dist / math.sqrt(gt_dist[0]**2 + gt_dist[1]**2))*100\n",
        "                print(\"Gt dist:\", gt_dist)\n",
        "                print(\"Pred dist:\", pred_dist)\n",
        "            if velos:\n",
        "                gt_velo = velos[gts.index(gt)]\n",
        "                pred_velo = calc_velocity(clip_num, [], pred, 5)\n",
        "                euclid_velo = calc_euclid_dist(gt_velo, pred_velo)\n",
        "                velo_sum += euclid_velo\n",
        "                velo_pc_sum += (euclid_velo / math.sqrt(gt_velo[0]**2 + gt_velo[1]**2))*100\n",
        "                print(\"Gt velo:\", gt_velo)\n",
        "                print(\"Pred velo:\", pred_velo)\n",
        "        if num_detected > 0:\n",
        "            jaccard_eval = jaccard_sum / num_detected\n",
        "            distance_eval = distance_sum / num_detected\n",
        "            distance_pc_eval = distance_pc_sum / num_detected\n",
        "            velocity_eval = velo_sum / num_detected\n",
        "            velocity_pc_eval = velo_pc_sum / num_detected\n",
        "\n",
        "    return (tp_eval, fp_eval, jaccard_eval, distance_eval, distance_pc_eval, velocity_eval, velocity_pc_eval)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESoaZ3xGbZkn"
      },
      "source": [
        "# returns the RGB version of the image and a list of bounding boxes\n",
        "# representing vehicle detections. Detections can be shown with show_img=True\n",
        "def detect_cnn(img):\n",
        "    bboxes = []\n",
        "    pred = pred_model.detect([img], verbose=0)[0]\n",
        "    masks = pred['masks']\n",
        "\n",
        "    # mrcnn.visualize.display_instances(image=image, \n",
        "    #                                   boxes=pred['rois'], \n",
        "    #                                   masks=pred['masks'], \n",
        "    #                                   class_ids=pred['class_ids'], \n",
        "    #                                   class_names=CLASS_NAMES, \n",
        "    #                                   scores=pred['scores'])\n",
        "    for mask in np.transpose(masks, (2, 0, 1)):\n",
        "        y_vals, x_vals = np.nonzero(mask == True)\n",
        "        x1 = min(x_vals)\n",
        "        x2 = max(x_vals)\n",
        "        y1 = min(y_vals)\n",
        "        y2 = max(y_vals)\n",
        "        bboxes.append((x1, x2, y1, y2))\n",
        "\n",
        "    return bboxes\n",
        "\n",
        "# detection_mode can be \"detection_only\", \"velocity\", or \"distance\"\n",
        "def show_detections(img, bboxes, clip_num, mode=[], save_file=False):\n",
        "    filename = f'{str(clip_num)}.jpg'\n",
        "\n",
        "    detections = []\n",
        "    if 'velocity' in mode:\n",
        "        for i in range(1, 41):\n",
        "            f'{str(i).zfill(3)}.jpg'\n",
        "            img_file = os.path.join(TESTING_DIR, str(clip_num), 'imgs', f'{str(i).zfill(3)}.jpg')\n",
        "            img = cv2.imread(img_file)\n",
        "            img = cv2.cvtColor(img, COLOR_SPACE)\n",
        "            detections.append(detect_cnn(img.copy()))\n",
        "\n",
        "    img_data = []\n",
        "    for bbox in bboxes:\n",
        "        x1, x2, y1, y2 = bbox\n",
        "        calc_dist = calc_distance(bbox)\n",
        "        dist = [round(d, 2) for d in calc_dist]\n",
        "        cv2.rectangle(img,(x1, y1),(x2, y2),(0,255,0),3)\n",
        "\n",
        "        if \"distance\" in mode:\n",
        "            label = f\"pos:({dist[0]}, {dist[1]})m\"\n",
        "            cv2.putText(img, label, (x1, y1-15), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
        "\n",
        "        car = {}\n",
        "        car['velocity'] = [0, 0]\n",
        "\n",
        "        if detections:\n",
        "            velo = calc_velocity(clip_num, detections, bbox, 5)\n",
        "            car['velocity'] = velo\n",
        "            velo[0] = round(velo[0], 2)\n",
        "            velo[1] = round(velo[1], 2)\n",
        "            label = f\"v:({velo[0]}, {velo[1]}) m/s\"\n",
        "            if \"distance\" in mode:\n",
        "                cv2.putText(img, label, (x1, y1-30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
        "            else:\n",
        "                cv2.putText(img, label, (x1, y1-15), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
        "        \n",
        "        car['bbox'] = {'top': int(y1), 'right': int(x2), 'left': int(x1), 'bottom': int(y2)}\n",
        "        car['position'] = calc_dist\n",
        "        img_data.append(car)\n",
        "\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    if save_file:\n",
        "        save_dir = os.path.join(TESTING_DIR, '..', 'preds')\n",
        "        if not os.path.isdir(save_dir):\n",
        "            os.makedirs(save_dir)\n",
        "        save_file = os.path.join(save_dir, f'{str(clip_num)}.jpg')\n",
        "        conv_img = cv2.cvtColor(img.copy(), cv2.COLOR_RGB2BGR)\n",
        "        cv2.imwrite(save_file, conv_img)\n",
        "\n",
        "    return img_data\n",
        "\n",
        "# runs the detection and evaluation for each test file in the given folder\n",
        "def make_predictions(data_dir, detection_mode=[], show_img=False, show_all=False, my_evaluate=False, save=False, subset=[]):\n",
        "    global velo_cache\n",
        "    velo_cache = {}\n",
        "    pred_data = []\n",
        "    distances = []\n",
        "    annotations, imgs, distances, velos = get_data(data_dir)\n",
        "    evaluations = []\n",
        "    print(len(imgs), len(annotations))\n",
        "    for i, (img, gts) in enumerate(list(zip(imgs, annotations))):\n",
        "        #if i < 228:\n",
        "        #    continue\n",
        "        bboxes = detect_cnn(img.copy())\n",
        "        to_show = bboxes\n",
        "        if show_img:\n",
        "            # only show expected detections\n",
        "            if not show_all and bboxes:\n",
        "                to_show = get_accurate_predictions(bboxes, gts)\n",
        "                to_show = [x[0] for x in to_show]\n",
        "            img_pred_data = show_detections(img.copy(), to_show, i+1, detection_mode, save_file=True)\n",
        "            pred_data.append(img_pred_data)\n",
        "\n",
        "        if my_evaluate:\n",
        "            evaluation = evaluate(i+1, bboxes, gts, mode='all', dists=distances[i], velos=velos[i])\n",
        "            print(\"True Positive:\", evaluation[0])\n",
        "            print(\"False Positive:\", evaluation[1])\n",
        "            print(\"Jaccard Index:\", evaluation[2])\n",
        "            print(\"Distance Error (m):\", evaluation[3])\n",
        "            print(\"Distance Error (%):\", evaluation[4])\n",
        "            print(\"Velocity Error (m):\", evaluation[5])\n",
        "            print(\"Velocity Error (%):\", evaluation[6])\n",
        "            evaluations.append(evaluation)\n",
        "    if my_evaluate:\n",
        "        print(\"\\n\")\n",
        "        print(\"True Positives Average:\", sum([e[0] for e in evaluations]) / len(evaluations))\n",
        "        print(\"False Positives Average:\", sum([e[1] for e in evaluations]) / len(evaluations))\n",
        "        print(\"Jaccard Index Average:\", sum([e[2] for e in evaluations]) / len(evaluations))\n",
        "        print(\"Distance Error Average (m):\", sum([e[3] for e in evaluations]) / len(evaluations))\n",
        "        print(\"Distance Error Average (%):\", sum([e[4] for e in evaluations]) / len(evaluations))\n",
        "        print(\"Velocity Error Average (m):\", sum([e[5] for e in evaluations]) / len(evaluations))\n",
        "        print(\"Velocity Error Average (%):\", sum([e[6] for e in evaluations]) / len(evaluations))\n",
        "    \n",
        "    if save:\n",
        "        with open(os.path.join(TESTING_DIR, '..', 'pred.json'), 'w+') as f:\n",
        "            json.dump(pred_data, f)\n",
        "    return pred_data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30V90_TcbZko"
      },
      "source": [
        "preds = make_predictions(TESTING_DIR, detection_mode=[\"distance\", \"velocity\"], show_img=True, show_all=False, my_evaluate=True, save=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPONdUvol0sD"
      },
      "source": [
        "VeloEval.bench_one_submit(os.path.join(TESTING_DIR, '..', 'pred.json'), os.path.join(TESTING_DIR, '..', 'gt.json'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8igviTOKxXJ"
      },
      "source": [
        "## Demo Run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "516CMRqRsGUc"
      },
      "source": [
        "preds = make_predictions(TESTING_DIR, detection_mode=[\"distance\", \"velocity\"], show_img=True, show_all=False, my_evaluate=True, save=True, subset=[10, 23, 26, 191, 29, 43, 44, 71, 83, 141])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}