{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from joblib import load\n",
    "\n",
    "TEST = 0\n",
    "TRAIN = 1\n",
    "SUPP = 2\n",
    "setMap = [\"test\", \"train\", \"supp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ceebs importing\n",
    "def slide_window(img, window_shape, step, eval_func):\n",
    "    matches = []\n",
    "    print(f\"\\nwindow of size {window_shape[0]} x {window_shape[1]}\", flush=True)\n",
    "    for start_row in tqdm(range(0, img.shape[0], step[1])):\n",
    "        for start_col in range(0, img.shape[1], step[0]):\n",
    "            extract = img[start_row : start_row + window_shape[1], start_col : start_col + window_shape[0]]\n",
    "            try:\n",
    "                if eval_func(extract, (start_col, start_row)):\n",
    "                    matches.append((start_col, start_row))\n",
    "            except:\n",
    "                print(extract)\n",
    "                print(window_shape)\n",
    "                print(img.shape)\n",
    "                print(start_row, start_row + window_shape[1], start_col, start_col + window_shape[0])\n",
    "                raise Exception\n",
    "    print(f\"\\n{len(matches)} matches\")\n",
    "    return matches\n",
    "\n",
    "def multi_level_detect(img, min_window, max_window_width, factor, step_ratio, eval_func):\n",
    "    window = np.array(min_window)\n",
    "    boxes = []\n",
    "    while window[0] <= max_window_width:\n",
    "        step = np.rint(window * step_ratio).astype(int)\n",
    "        matches = slide_window(img, window, step, eval_func)\n",
    "        boxes += [(location, *window) for location in matches]\n",
    "        window = np.rint(window * factor).astype(int)\n",
    "    return boxes\n",
    "\n",
    "def cnn_eval(img, loc):\n",
    "    model = load('model.joblib')\n",
    "    resized = cv.resize(img, (40, 30))\n",
    "    return model.predict(np.array([resized]))[0] > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_boxes_to_vertices(boxes):\n",
    "    vertices = []\n",
    "    for box in boxes:\n",
    "        left = box[0][0]\n",
    "        right = box[0][0] + box[1]\n",
    "        top = box[0][1]\n",
    "        bot = box[0][1] + box[2]\n",
    "        vertices += [[(left, bot), (left, top), (right, top), (right, bot)]]\n",
    "    \n",
    "    return np.array(vertices)\n",
    "    \n",
    "def mask_vehicles(img, mask, ignore_mask_color):\n",
    "    rgb = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "    # rohans parameters\n",
    "    boxes = multi_level_detect(rgb, (80, 60), 400, 1.5, 0.3, cnn_eval)\n",
    "    vertices = convert_boxes_to_vertices(boxes)\n",
    "    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Preprocess(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    return cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "def OtsuImg(img):\n",
    "    ret, otsu = cv2.threshold(img,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    return otsu\n",
    "\n",
    "def transformThreshold(img, thresholdValue):\n",
    "    outputImage = np.full(img.shape, 0)\n",
    "\n",
    "    for i in range(outputImage.shape[0]):\n",
    "        for j in range(outputImage.shape[1]):\n",
    "            outputImage[i,j] = 255 * (img[i,j] > thresholdValue)\n",
    "    \n",
    "    return np.uint8(outputImage)\n",
    "\n",
    "\n",
    "def Canny(img):\n",
    "    return cv2.Canny(img, 100, 200)\n",
    "\n",
    "def RegionOfInterest(img):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "    \n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    \"\"\"\n",
    "\n",
    "    lowerLeftPoint = [0, 720]\n",
    "    lowerRightPoint = [1280, 720]\n",
    "    upperLeftPoint = [120, 360]\n",
    "    upperRightPoint = [1100, 360]\n",
    "\n",
    "    vertices = np.array([[lowerLeftPoint, upperLeftPoint, upperRightPoint, lowerRightPoint]], dtype=np.int32)\n",
    "\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with \n",
    "    #depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    masked_image = maskVehicles(img, mask, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "def draw_lines(img, lines, color=[255, 0, 0], thickness=2):\n",
    "    try:\n",
    "        if lines.any():\n",
    "            for line in lines:\n",
    "                if line.any():\n",
    "                    for x1,y1,x2,y2 in line:\n",
    "                        cv2.line(img, (x1, y1), (x2, y2), color, thickness)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "\n",
    "def hough_lines(img):\n",
    "    \"\"\"\n",
    "    `img` should be the output of a Canny transform.\n",
    "        \n",
    "    Returns an image with hough lines drawn.\n",
    "    \"\"\"\n",
    "    rho = 1\n",
    "    theta = np.pi/180\n",
    "    threshold = 30\n",
    "    min_line_len = 20 \n",
    "    max_line_gap = 20\n",
    "\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]))\n",
    "    \n",
    "    line_img = np.zeros((*img.shape, 3), dtype=np.uint8)\n",
    "    \n",
    "    draw_lines(line_img, lines)\n",
    "    return line_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImage(n, set):\n",
    "    path = \"benchmark_velocity_supp/supp_img/\" + str(n).zfill(4) + \".jpg\"\n",
    "    if (set == TEST or set == TRAIN):\n",
    "        path = \"benchmark_velocity_\" + setMap[set] + \"/clips/\" + str(n) + \"/imgs/040.jpg\"\n",
    "    \n",
    "    print(path)\n",
    "    img = cv2.imread(path)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,100):\n",
    "    print(i)\n",
    "    img = getImage(i, TRAIN)\n",
    "    img = RegionOfInterest(img)\n",
    "    preprocessedImg = Preprocess(img)\n",
    "    thresholdImg = transformThreshold(preprocessedImg, 140)\n",
    "    thresholdImg2 = OtsuImg(preprocessedImg)\n",
    "\n",
    "    cannyImg = Canny(np.uint8(thresholdImg))\n",
    "    maskedImg = RegionOfInterest(cannyImg)\n",
    "    houged = hough_lines(maskedImg)\n",
    "\n",
    "    if (not os.path.exists('output')):\n",
    "        print('creating output dir')\n",
    "        os.mkdir('./output')\n",
    "\n",
    "    cv2.imwrite(\"output/output\" + str(i) + \".jpg\", np.uint8(RegionOfInterest(thresholdImg)))\n",
    "    cv2.imwrite(\"output/output\" + str(i) + \"Original.jpg\", preprocessedImg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
