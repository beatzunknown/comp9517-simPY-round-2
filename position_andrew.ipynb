{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP9517 Project: Individual Component\n",
    "By Andrew Timkov (z5169762)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "import pickle\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import ndimage as ndi\n",
    "from scipy.ndimage.measurements import label\n",
    "from skimage.feature import canny\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_FILE = \"model.dat\"\n",
    "SCALER_FILE = \"scaler.dat\"\n",
    "HOG_WINDOW_SIZE = (128, 128)\n",
    "HEATMAP_THRESH = 10\n",
    "# The colour space used for HOG\n",
    "COLOR_SPACE = cv2.COLOR_BGR2HSV\n",
    "plt.rcParams['figure.figsize'] = [16, 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hog = cv2.HOGDescriptor(\"hog.xml\")\n",
    "svm = None\n",
    "scaler = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize any image crop to the fixed HOG window size (128x128)\n",
    "def resize(img):\n",
    "    if img.shape[:2] != HOG_WINDOW_SIZE:\n",
    "        return cv2.resize(img, HOG_WINDOW_SIZE, cv2.INTER_AREA)\n",
    "    return img\n",
    "\n",
    "# Retrieve a feature vector for a given image\n",
    "# Feature vector will always include the HOG descriptor,\n",
    "# but HSV and RGB histograms can be disabled\n",
    "def get_features(img, use_hsv=True, use_rgb=True):\n",
    "    global hog\n",
    "    img = resize(img)\n",
    "\n",
    "    feature_vector = hog.compute(img)[:,0]\n",
    "    \n",
    "    if use_hsv:\n",
    "        h, _ = np.histogram(img[:,:,0], 256, [0, 256])\n",
    "        s, _ = np.histogram(img[:,:,1], 256, [0, 256])\n",
    "        v, _ = np.histogram(img[:,:,2], 256, [0, 256])\n",
    "        feature_vector = np.concatenate((feature_vector, h, s, v))\n",
    "    \n",
    "    if use_rgb:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_HSV2RGB)\n",
    "        r, _ = np.histogram(img[:,:,0], 256, [0, 256])\n",
    "        g, _ = np.histogram(img[:,:,1], 256, [0, 256])\n",
    "        b, _ = np.histogram(img[:,:,2], 256, [0, 256])\n",
    "        feature_vector = np.concatenate((feature_vector, r, g, b))\n",
    "    \n",
    "    return feature_vector\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some hardcoded crop areas in the images\n",
    "nonmatch_bounds = [\n",
    "    (720, 784, 260, 324), # middle where sky meets trees/ground\n",
    "    (60, 188, 580, 708), # middle just sky\n",
    "    (1024, 1280, 200, 456), # right side road+trees\n",
    "    (0, 256, 240, 496), # left side road + trees + other lane\n",
    "    (520, 648, 440, 568), # middle of road (likely lane lines)\n",
    "    (700, 764, 470, 534) # middle of road (likely just plain road)\n",
    "]\n",
    "# hardcoded band of negative crop areas, where there a lot of\n",
    "# false positives were occurring\n",
    "for x1 in range(0, 1280-128, 256):\n",
    "    nonmatch_bounds.append((x1, x1+64, 340, 468))\n",
    "\n",
    "# Check if two given rectangles are overlapping\n",
    "def is_overlapping(a, b):\n",
    "    ax1, ax2, ay1, ay2 = a\n",
    "    bx1, bx2, by1, by2 = b\n",
    "    \n",
    "    # left side of one is after right side of other\n",
    "    if ax1 >= bx2 or bx1 >= ax2:\n",
    "        return False\n",
    "    \n",
    "    # top side of one is below bottom side of other\n",
    "    if ay1 >= by2 or by1 >= ay2:\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "# retrieve feature vectors, annotations and images from\n",
    "# a list of labels and data files\n",
    "def parse_data(img_files, label_files, pos_data=[]):\n",
    "    match_data, nonmatch_data, annotations, imgs = [], [], [], []\n",
    "    iter_data = list(zip(img_files, label_files))\n",
    "    random.shuffle(iter_data)\n",
    "    for i, (img_file, label_file) in enumerate(iter_data):\n",
    "        label = None\n",
    "        if not os.path.isfile(label_file):\n",
    "            continue\n",
    "        with open(label_file, 'r') as f:\n",
    "            label = json.load(f)\n",
    "        if label is None:\n",
    "            continue\n",
    "            \n",
    "        img = cv2.imread(img_file)\n",
    "        img = cv2.cvtColor(img, COLOR_SPACE)\n",
    "        imgs.append(img)\n",
    "        img_annotations = []\n",
    "        nonmatches = nonmatch_bounds.copy()\n",
    "        \n",
    "        for label_bounds in label:\n",
    "            bbox = label_bounds['bbox']\n",
    "            x1 = math.floor(bbox['left'])\n",
    "            x2 = math.ceil(bbox['right'])\n",
    "            y1 = math.floor(bbox['top'])\n",
    "            y2 = math.ceil(bbox['bottom'])\n",
    "            img_annotations.append((x1, x2, y1, y2))\n",
    "            dim_diff = (x2-x1) - (y2-y1)\n",
    "            size = x2 - x1\n",
    "            if x1 >= x2 or y1 >= y2:\n",
    "                continue\n",
    "            y1 -= math.floor(dim_diff/2)\n",
    "            y2 += math.ceil(dim_diff/2)\n",
    "            if y1 < 0 or y2 > img.shape[0]:\n",
    "                continue\n",
    "\n",
    "            match_img = img[y1:y2, x1:x2]\n",
    "            match_data.append(get_features(match_img))\n",
    "            nonmatches = [n for n in nonmatches if not is_overlapping(n, (x1, x2, y1, y2))]\n",
    "        \n",
    "        for x1, x2, y1, y2 in nonmatches:\n",
    "            nonmatch_img = img[y1:y2, x1:x2]\n",
    "            nonmatch_data.append(get_features(nonmatch_img))\n",
    "        \n",
    "        annotations.append(img_annotations)\n",
    "    \n",
    "    return (match_data, nonmatch_data, annotations, imgs)\n",
    "\n",
    "def get_data(file_dir, get_pos=False):\n",
    "    file_dir = os.path.abspath(file_dir)\n",
    "    img_files, label_files, pos_data = [], [], []\n",
    "    for clip_num in os.listdir(file_dir):\n",
    "        clip_path = os.path.join(file_dir, clip_num)\n",
    "        if os.path.isdir(clip_path):\n",
    "            img_files.append(os.path.join(clip_path, \"imgs\", \"040.jpg\"))\n",
    "            label_files.append(os.path.join(clip_path, \"annotation.json\"))\n",
    "            pos_data.append(clip_num)\n",
    "    \n",
    "    if get_pos:\n",
    "        return parse_data(img_files, label_files, pos_data)\n",
    "    return parse_data(img_files, label_files)\n",
    "\n",
    "# Get supplementary data (not used at the moment)\n",
    "def get_supp_data(file_dir):\n",
    "    match_data = []\n",
    "    nonmatch_data = []\n",
    "    annotations = []\n",
    "    imgs = []\n",
    "    file_dir = os.path.abspath(file_dir)\n",
    "    img_files, label_file = [], os.path.join(file_dir, \"annotation.json\")\n",
    "    with open(label_file, 'r') as f:\n",
    "            label_data = json.load(f)\n",
    "    \n",
    "\n",
    "    for entry in label_data[1000:2000]:\n",
    "        img_file = os.path.join(file_dir, entry['file_name'])\n",
    "        if not os.path.isfile(img_file):\n",
    "            continue\n",
    "        img = cv2.imread(img_file)\n",
    "        img = cv2.cvtColor(img, COLOR_SPACE)\n",
    "        imgs.append(img)\n",
    "        nonmatches = nonmatch_bounds.copy()\n",
    "        \n",
    "        label = entry['bbox']\n",
    "        \n",
    "        for label_bounds in label:\n",
    "            x1 = math.floor(label_bounds['left'])\n",
    "            x2 = math.ceil(label_bounds['right'])\n",
    "            y1 = math.floor(label_bounds['top'])\n",
    "            y2 = math.ceil(label_bounds['bottom'])\n",
    "            annotations.append((x1, x2, y1, y2))\n",
    "            dim_diff = (x2-x1) - (y2-y1)\n",
    "            size = x2 - x1\n",
    "            if x1 >= x2 or y1 >= y2:\n",
    "                continue\n",
    "            y1 -= math.floor(dim_diff/2)\n",
    "            y2 += math.ceil(dim_diff/2)\n",
    "            if y1 < 0 or y2 > img.shape[0]:\n",
    "                continue\n",
    "            #plt.imshow(img)\n",
    "            #plt.show()\n",
    "            #cv2.waitKey(0)\n",
    "            match_img = img[y1:y2, x1:x2]\n",
    "            match_data.append(get_features(match_img))\n",
    "            nonmatches = [n for n in nonmatches if not is_overlapping(n, (x1, x2, y1, y2))]\n",
    "        \n",
    "        for x1, x2, y1, y2 in nonmatches:\n",
    "            nonmatch_img = img[y1:y2, x1:x2]\n",
    "            nonmatch_data.append(get_features(nonmatch_img))\n",
    "    \n",
    "    return (match_data, nonmatch_data, annotations, imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise a data scaler (standardisation or normalisation)\n",
    "def init_scaler(match_data, nonmatch_data, scaler=\"standardise\"):\n",
    "    if scaler == \"standardise\":\n",
    "        return StandardScaler().fit(np.concatenate((match_data, nonmatch_data)))\n",
    "    else:\n",
    "        return MinMaxScaler().fit(np.concatenate((match_data, nonmatch_data)))\n",
    "    \n",
    "def scale(scaler, data):\n",
    "    return scaler.transform(data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the classifier\n",
    "# use_supp: whether or not to use supplementary data\n",
    "# get_stored: whether or not to load pickled classifier\n",
    "def train_classifier(use_supp=False, get_stored=False, scaler_type=\"standardise\"):\n",
    "    global scaler, svm\n",
    "    if get_stored:\n",
    "        model_dir = os.path.abspath(MODEL_FILE)\n",
    "        if os.path.isfile(model_dir):\n",
    "            svm = pickle.load(open(MODEL_FILE, 'rb'))\n",
    "            scaler_dir = os.path.abspath(SCALER_FILE)\n",
    "            if os.path.isfile(scaler_dir):\n",
    "                scaler = pickle.load(open(SCALER_FILE, 'rb'))\n",
    "                return\n",
    "            \n",
    "    match_data, nonmatch_data, annotations, imgs = get_data(\"benchmark_velocity_train\\\\clips\\\\\")\n",
    "    if use_supp:\n",
    "        supp_match_data, supp_nonmatch_data, supp_annotations, supp_imgs = get_supp_data(\"benchmark_velocity_supp\\\\\")\n",
    "        match_data = np.concatenate((match_data, supp_match_data))\n",
    "        nonmatch_data = np.concatenate((nonmatch_data, supp_nonmatch_data))\n",
    "    if not get_stored or scaler is None:\n",
    "        scaler = init_scaler(match_data, nonmatch_data, scaler_type)\n",
    "        pickle.dump(scaler, open(SCALER_FILE, 'wb+'))\n",
    "\n",
    "    match_data = scale(scaler, match_data)\n",
    "    nonmatch_data = scale(scaler, nonmatch_data)\n",
    "    match_labels = np.ones(match_data.shape[0], dtype=int)\n",
    "    nonmatch_labels = np.zeros(nonmatch_data.shape[0], dtype=int)\n",
    "    training_data = np.concatenate((match_data, nonmatch_data))\n",
    "    training_labels = np.concatenate((match_labels, nonmatch_labels))\n",
    "\n",
    "    svm = LinearSVC(dual=False)\n",
    "    svm.fit(training_data, training_labels)\n",
    "    pickle.dump(svm, open(MODEL_FILE, 'wb+'))\n",
    "    \n",
    "    match_res = svm.predict(match_data)\n",
    "    nonmatch_res = svm.predict(nonmatch_data)\n",
    "    false_neg = np.sum(match_res != 1)\n",
    "    false_pos = np.sum(nonmatch_res == 1)\n",
    "    print(\"Positive data result:\", 1 - (false_neg / float(match_data.shape[0])))\n",
    "    print(\"Negative data result:\", 1 - (false_pos / float(nonmatch_data.shape[0])))\n",
    "\n",
    "# test the classifier on the dataset in a given folder\n",
    "def test_classifier(data_dir):\n",
    "    global scaler, svm\n",
    "    match_data, nonmatch_data, annotations, imgs = get_data(data_dir)\n",
    "\n",
    "    match_data = scale(scaler, match_data)\n",
    "    nonmatch_data = scale(scaler, nonmatch_data)\n",
    "    match_labels = np.ones(match_data.shape[0], dtype=int)\n",
    "    nonmatch_labels = np.zeros(nonmatch_data.shape[0], dtype=int)\n",
    "    training_data = np.concatenate((match_data, nonmatch_data))\n",
    "    training_labels = np.concatenate((match_labels, nonmatch_labels))\n",
    "\n",
    "    match_res = svm.predict(match_data)\n",
    "    nonmatch_res = svm.predict(nonmatch_data)\n",
    "    false_neg = np.sum(match_res != 1)\n",
    "    false_pos = np.sum(nonmatch_res == 1)\n",
    "    print(\"Positive data result:\", 1 - (false_neg / float(match_data.shape[0])))\n",
    "    print(\"Negative data result:\", 1 - (false_pos / float(nonmatch_data.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_classifier(use_supp=False, get_stored=False, scaler_type=\"standardise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_classifier(\"benchmark_velocity_test\\\\clips\\\\\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns coordinates of the sliding windows in an image\n",
    "def get_sliding_windows(img):\n",
    "    h, w, _ = img.shape\n",
    "    start_y = 230\n",
    "    end_y = 614\n",
    "    y_range = end_y - start_y\n",
    "    overlap = 0.5\n",
    "    scale = 0.5\n",
    "    size = 256\n",
    "    num_layers = int((1/(1-overlap))+2)\n",
    "    \n",
    "    windows = []\n",
    "    \n",
    "    while size >= 32:\n",
    "        # 3 layers of each window size\n",
    "        for i in range(num_layers):\n",
    "            y1 = start_y + int(i*size*(1-overlap))\n",
    "            y2 = y1 + size\n",
    "            if y2 > h:\n",
    "                break\n",
    "            for x1 in range(0, w-size+1, int(size*(1-overlap))):\n",
    "                x2 = x1 + size\n",
    "                windows.append((x1, x2, y1, y2))\n",
    "        size = int(size*scale)\n",
    "        start_y += int(size*scale)\n",
    "    \n",
    "    return windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculated IOU / Jaccard Index\n",
    "def intersection_over_union(a, b):\n",
    "    ax1, ax2, ay1, ay2 = a\n",
    "    bx1, bx2, by1, by2 = b\n",
    "    a_area = (ax2 - ax1) * (ay2 - ay1)\n",
    "    b_area = (bx2 - bx1) * (by2 - by1)\n",
    "\n",
    "    inter_width = min(ax2, bx2) - max(ax1, bx1)\n",
    "    inter_height = min(ay2, by2) - max(ay1, by1)\n",
    "    if inter_width > 0 and inter_height > 0:\n",
    "        inter_area = inter_width * inter_height\n",
    "    else:\n",
    "        inter_area = 0\n",
    "    \n",
    "    union_area = a_area + b_area - inter_area\n",
    "    return inter_area / union_area\n",
    "\n",
    "# vehicle prediction evaluation\n",
    "# pred: list of predicted boxes\n",
    "# gt: list of ground truth boxes\n",
    "def evaluate(pred, gts, mode='tp'):\n",
    "    # true positives\n",
    "    if mode == 'tp':\n",
    "        num_detected = 0\n",
    "        for gt in gts:\n",
    "            num_detected += any([is_overlapping(p, gt) for p in pred])\n",
    "        return num_detected / len(gts)\n",
    "    # false positives\n",
    "    elif mode == 'fp':\n",
    "        num_fp = len(pred)\n",
    "        if num_fp == 0:\n",
    "            return 0\n",
    "        for p in pred:\n",
    "            num_fp -= any([is_overlapping(p, gt) for gt in gts])\n",
    "        return num_fp / len(pred)\n",
    "    # jaccard index\n",
    "    elif mode == 'jaccard':\n",
    "        num_detected = 0\n",
    "        jaccard_sum = 0\n",
    "        for p in pred:\n",
    "            detected = [gt for gt in gts if is_overlapping(p, gt)]\n",
    "            if detected:\n",
    "                jaccards = [intersection_over_union(p, d) for d in detected]\n",
    "                num_detected += len(jaccards)\n",
    "                jaccard_sum += sum(jaccards)\n",
    "        if num_detected == 0:\n",
    "            return 0\n",
    "        return jaccard_sum / num_detected\n",
    "    tp_eval = evaluate(pred, gts, mode='tp')\n",
    "    fp_eval = evaluate(pred, gts, mode='fp')\n",
    "    jaccard_eval = evaluate(pred, gts, mode='jaccard')\n",
    "    return (tp_eval, fp_eval, jaccard_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_heatmap(img, windows):\n",
    "    heatmap = np.zeros(img.shape, dtype=np.uint8)\n",
    "    # Add 5 to pixel intensity for each window\n",
    "    for x1, x2, y1, y2 in windows:\n",
    "        heatmap[y1:y2, x1:x2] += 5\n",
    "    heatmap = cv2.medianBlur(heatmap, ksize=11)\n",
    "    heatmap = cv2.dilate(heatmap, np.ones((11,11), dtype=np.uint8))\n",
    "    # heatmap threshold filtering\n",
    "    heatmap[heatmap < HEATMAP_THRESH] = 0\n",
    "    return heatmap\n",
    "\n",
    "# returns the RGB version of the image and a list of bounding boxes\n",
    "# representing vehicle detections. Detections can be shown with show_img=True\n",
    "def detect(img, show_img=False):\n",
    "    windows = get_sliding_windows(img)\n",
    "    features = [get_features(img[y1:y2,x1:x2]) for x1, x2, y1, y2 in windows]\n",
    "    features_scaled = scale(scaler, features)\n",
    "    predictions = svm.predict(features_scaled)\n",
    "    windows = [windows[i] for i in np.argwhere(predictions==1)[:,0]]\n",
    "    heatmap = generate_heatmap(img, windows)\n",
    "    labelled_heatmap, obj_count = label(heatmap)\n",
    "    bboxes = []\n",
    "    \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_HSV2RGB)\n",
    "    \n",
    "    for o in range(obj_count):\n",
    "        y_vals, x_vals, channels = np.nonzero(labelled_heatmap == o+1)\n",
    "        x1 = min(x_vals)\n",
    "        x2 = max(x_vals)\n",
    "        y1 = min(y_vals)\n",
    "        y2 = max(y_vals)\n",
    "        dx = x2 - x1\n",
    "        dy = y2 - y1\n",
    "        # filter out obvious wide false positives\n",
    "        if dx > 300 and dx > 3*dy:\n",
    "            continue\n",
    "        bboxes.append((x1, x2, y1, y2))\n",
    "        cv2.rectangle(img,(x1, y1),(x2, y2),(0,255,0),3)\n",
    "\n",
    "    if show_img:\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    return (img, bboxes)\n",
    "\n",
    "# runs the detection and evaluation for each test file in the given folder\n",
    "def run_evaluations(data_dir, show_img=False):\n",
    "    match_data, nonmatch_data, annotations, imgs = get_data(data_dir)\n",
    "    evaluations = []\n",
    "    for im, im_annotations in zip(imgs, annotations):\n",
    "        img, bboxes = detect(im.copy(), show_img=show_img)\n",
    "        evaluation = evaluate(bboxes, im_annotations, mode='all')\n",
    "        print(\"True Positive:\", evaluation[0])\n",
    "        print(\"False Positive:\", evaluation[1])\n",
    "        print(\"Jaccard Index:\", evaluation[2])\n",
    "        evaluations.append(evaluation)\n",
    "    print(\"\\n\")\n",
    "    print(\"True Positives:\", sum([e[0] for e in evaluations]) / len(evaluations))\n",
    "    print(\"False Positives:\", sum([e[1] for e in evaluations]) / len(evaluations))\n",
    "    print(\"Jaccard Index:\", sum([e[2] for e in evaluations]) / len(evaluations))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_evaluations(\"benchmark_velocity_test\\\\clips\\\\\", show_img=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_distance(img):\n",
    "    x1, x2, y1, y2 = img\n",
    "    fx = 714.1526\n",
    "    fy = 710.3725\n",
    "    x0 = 713.85\n",
    "    y0 = 327\n",
    "    car_width = 1.8\n",
    "    car_height = 1.5\n",
    "    \n",
    "    d = car_width * fx / (x2 - x1)\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
